{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC9PHXgv6o9n",
        "outputId": "390376d9-4917-4ae2-9100-59315737ef0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting perlin_noise\n",
            "  Downloading perlin_noise-1.12-py3-none-any.whl (5.3 kB)\n",
            "Installing collected packages: perlin_noise\n",
            "Successfully installed perlin_noise-1.12\n"
          ]
        }
      ],
      "source": [
        "!pip install perlin_noise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from scipy.signal import argrelextrema\n",
        "import pickle\n",
        "from perlin_noise import PerlinNoise\n",
        "from scipy.integrate import simps\n",
        "from scipy.integrate import simps\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.integrate import cumtrapz"
      ],
      "metadata": {
        "id": "e4mHhbNk69je"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eye Data Collection\n",
        "\n",
        "**Eyes Closed Example**\n",
        "\n",
        "![eye_bd.png](https://drive.google.com/uc?id=1T6LzclN79b4JN2nhEHv8F_knpQmrga2W)\n",
        "\n",
        "**Eyes Open Example**\n",
        "\n",
        "![eye_bd.png](https://drive.google.com/uc?id=1VYURFTQxTUJ38P-n0-Wluz3lugGcwB6u)\n",
        "\n"
      ],
      "metadata": {
        "id": "2rVxRMp6UG4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_eye_blink_peaks(df, column_name, threshold=0.7):\n",
        "    \"\"\"\n",
        "    Detects the peak of eye blinks.\n",
        "\n",
        "    :param df: DataFrame containing all blendshape data.\n",
        "    :param column_name: The name of the column to analyze for eye blinks.\n",
        "    :param threshold: The threshold value above which an eye blink is considered to have started.\n",
        "    :return: A list of frame numbers where the peak of eye blinks were detected.\n",
        "    \"\"\"\n",
        "    blink_peaks = []\n",
        "    in_blink = False\n",
        "    peak_value = 0\n",
        "    peak_frame = None\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        current_value = row[column_name]\n",
        "        if current_value > threshold and not in_blink:\n",
        "            # Start of a new blink\n",
        "            in_blink = True\n",
        "            peak_value = current_value\n",
        "            peak_frame = index\n",
        "        elif in_blink:\n",
        "            if current_value > peak_value:\n",
        "                # Update peak value and frame\n",
        "                peak_value = current_value\n",
        "                peak_frame = index\n",
        "            elif current_value <= threshold:\n",
        "                # End of a blink\n",
        "                blink_peaks.append(peak_frame)\n",
        "                in_blink = False\n",
        "\n",
        "    return blink_peaks\n",
        "\n",
        "def find_blink_duration(df, column_name, blink_peak_frames):\n",
        "    \"\"\"\n",
        "    Finds the duration of each blink.\n",
        "\n",
        "    :param df: DataFrame containing all blendshape data.\n",
        "    :param column_name: The name of the column to analyze for eye blinks.\n",
        "    :return: A list of blink duration.\n",
        "    \"\"\"\n",
        "    blink_durations = []\n",
        "\n",
        "    for peak_frame in blink_peak_frames:\n",
        "        # Initialize start and end frame to the peak frame\n",
        "        start_frame, end_frame = peak_frame, peak_frame\n",
        "\n",
        "        sharp_decrease = False\n",
        "        # Find start of blink: move left until the condition is met\n",
        "        while start_frame > 0:\n",
        "            diff = df[column_name].iloc[start_frame] - df[column_name].iloc[start_frame - 1]\n",
        "            if (sharp_decrease and diff <= 0.01) or (not sharp_decrease and diff <= 0):\n",
        "                break\n",
        "            if diff > 0.3:\n",
        "                sharp_decrease = True\n",
        "            start_frame -= 1\n",
        "\n",
        "        sharp_decrease = False\n",
        "        # Find end of blink: move right until the condition is met\n",
        "        while end_frame < len(df) - 1:\n",
        "            diff = df[column_name].iloc[end_frame] - df[column_name].iloc[end_frame + 1]\n",
        "            if (sharp_decrease and diff <= 0.01) or (not sharp_decrease and diff <= 0):\n",
        "                break\n",
        "            if diff > 0.3:\n",
        "                sharp_decrease = True\n",
        "            end_frame += 1\n",
        "\n",
        "        # Calculate duration\n",
        "        duration = end_frame - start_frame + 1\n",
        "        blink_durations.append(duration)\n",
        "\n",
        "    return blink_durations\n",
        "\n",
        "def find_half_max_jaw_open_frames(df, column_name):\n",
        "    \"\"\"\n",
        "    Finds the frames where the 'Jaw Open' value is half of its maximum in the dataset.\n",
        "\n",
        "    :param df: DataFrame containing all blendshape data.\n",
        "    :param column_name: The name of the column to analyze for jaw open.\n",
        "    :return: Two list of frame numbers where the jaw open value is half of its maximum, first one is unormalized, second one is normalized.\n",
        "    \"\"\"\n",
        "    max_value = df[column_name].max()\n",
        "    half_max_value = max_value / 2\n",
        "\n",
        "    # Identify frames where the value crosses half of the maximum\n",
        "    frames = []\n",
        "    for index, row in df.iterrows():\n",
        "        if abs(row[column_name] - half_max_value) < 0.05:  # Allowing a small tolerance\n",
        "            frames.append(index)\n",
        "\n",
        "    return [frames[0], frames[-1]], [frames[0]/len(df[column_name]), frames[-1]/len(df[column_name])]\n",
        "\n"
      ],
      "metadata": {
        "id": "hs5sUrnC0IXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![eye_bd.png](https://drive.google.com/uc?id=1PYEBJ8E0mizFihHDDn1w1s1bYQXSfpto)"
      ],
      "metadata": {
        "id": "8xokOvI_u0p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dictionaries and lists\n",
        "normalized_blink_frames = {}\n",
        "normalized_half_open_frames = {}\n",
        "unnormalized_half_open = []\n",
        "total_time = []\n",
        "num_blink = []\n",
        "durations = []\n",
        "blink_data = {}\n",
        "\n",
        "# Read and process each CSV file\n",
        "csv_files = glob.glob('*.csv')\n",
        "for file_path in csv_files:\n",
        "    data = pd.read_csv(file_path)\n",
        "    total_frames = len(data)\n",
        "\n",
        "    blink_peak_frames = detect_eye_blink_peaks(data, 'EyeBlinkLeft')\n",
        "    blink_durations = find_blink_duration(data, 'EyeBlinkLeft', blink_peak_frames)\n",
        "    unnorm_jaw, jaw_open_half_max_frames = find_half_max_jaw_open_frames(data, 'JawOpen')\n",
        "\n",
        "    normalized_blink_peak_frames = [frame / total_frames for frame in blink_peak_frames]\n",
        "    jaw_open_start, jaw_open_end = jaw_open_half_max_frames[0], jaw_open_half_max_frames[1]\n",
        "    temp = [[], [], []]\n",
        "\n",
        "    # Categorize normalized blink frames\n",
        "    for f in normalized_blink_peak_frames:\n",
        "        if f < jaw_open_start:\n",
        "            temp[0].append(f)\n",
        "        elif f > jaw_open_end:\n",
        "            temp[2].append(f)\n",
        "        else:\n",
        "            temp[1].append(f)\n",
        "\n",
        "    normalized_blink_frames[file_path] = temp\n",
        "    normalized_half_open_frames[file_path] = jaw_open_half_max_frames\n",
        "    unnormalized_half_open.append(unnorm_jaw)\n",
        "    total_time.append(total_frames)\n",
        "    num_blink.append([len(x) for x in temp])\n",
        "    durations += blink_durations\n",
        "\n",
        "    # Print file details\n",
        "    print(file_path)\n",
        "    print(\"jaw open frames\", unnorm_jaw)\n",
        "    print(\"peak\", blink_peak_frames)\n",
        "    print(\"number\", [len(x) for x in temp])\n",
        "    print(\"duration\", blink_durations, '\\n')\n",
        "\n",
        "xs = []\n",
        "\n",
        "for i, f in enumerate(normalized_blink_frames):\n",
        "    if len(normalized_blink_frames[f][0]) != 0:\n",
        "        length = normalized_half_open_frames[f][0]\n",
        "        for b in normalized_blink_frames[f][0]:\n",
        "            x = b / length\n",
        "            xs.append(x/4)\n",
        "\n",
        "    if len(normalized_blink_frames[f][1]) != 0:\n",
        "        length = normalized_half_open_frames[f][1] - normalized_half_open_frames[f][0]\n",
        "        for b in normalized_blink_frames[f][1]:\n",
        "            x = (b - normalized_half_open_frames[f][0]) / length\n",
        "            xs.append(x/2 + 0.25)\n",
        "\n",
        "    if len(normalized_blink_frames[f][2]) != 0:\n",
        "        length = 1 - normalized_half_open_frames[f][1]\n",
        "        for b in normalized_blink_frames[f][2]:\n",
        "            x = (b - normalized_half_open_frames[f][1]) / length\n",
        "            xs.append(x/4 + 0.75)"
      ],
      "metadata": {
        "id": "J_P3NEd0Cb5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blink Frequency\n",
        "\n"
      ],
      "metadata": {
        "id": "p08I-4ZS9TAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_over_all_times = []\n",
        "avg_over_mouth_open_times = []\n",
        "for i in range(len(total_time)):\n",
        "    if sum(num_blink[i]):\n",
        "        avg_over_all_times.append(total_time[i]/sum(num_blink[i]))\n",
        "    if num_blink[i][1]:\n",
        "        avg_over_mouth_open_times.append((unnormalized_half_open[i][1] - unnormalized_half_open[i][0])/num_blink[i][1])\n",
        "\n",
        "a = np.array(avg_over_all_times)\n",
        "print(\"Average over all time \", np.mean(np.array(a)))\n",
        "\n",
        "amot = np.array(avg_over_mouth_open_times)\n",
        "avg_time = np.mean(np.array(amot))\n",
        "print(\"Average over mouth open time \",avg_time)\n",
        "\n",
        "blink_data['avg_over_all_times'] = avg_over_all_times\n",
        "blink_data['avg_over_mouth_open_times'] = avg_over_mouth_open_times\n",
        "blink_data['avg_time'] = avg_time"
      ],
      "metadata": {
        "id": "Ydk4-mHQ9lYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blink Peak Occurrence"
      ],
      "metadata": {
        "id": "LcVGWnba90b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import make_interp_spline\n",
        "from scipy.integrate import simps\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.integrate import cumtrapz\n",
        "\n",
        "# Blink Peak\n",
        "x = np.array(xs)\n",
        "\n",
        "# Creating a histogram with bins=8\n",
        "hist, bin_edges = np.histogram(x, bins=8, density=True)\n",
        "\n",
        "# Midpoints of bins\n",
        "bin_midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "\n",
        "# Generating a smooth curve\n",
        "x_smooth = np.linspace(bin_midpoints.min(), bin_midpoints.max(), 300)\n",
        "y_smooth = make_interp_spline(bin_midpoints, hist)(x_smooth)\n",
        "\n",
        "# Calculate the area under the y_smooth curve\n",
        "area_under_curve = simps(y_smooth, x_smooth)\n",
        "\n",
        "# Normalize y_smooth to make it a PDF\n",
        "y_smooth_pdf = y_smooth / area_under_curve\n",
        "\n",
        "\n",
        "blink_data['peak'] = {'x_smooth': x_smooth, 'y_smooth_pdf': y_smooth_pdf}"
      ],
      "metadata": {
        "id": "RT7pUxBSCdvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1JaH6z4O5uHM01qwhCgYNA17VIHZLVwuV\" width=\"500\" alt=\"eye_bd.png\">\n",
        "<img src=\"https://drive.google.com/uc?id=1crHiwWIQ--4_M86qo8WPdJh9C8mt7sJo\" width=\"500\" alt=\"eye_bd.png\">\n"
      ],
      "metadata": {
        "id": "eC19viztZrKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blink Duration"
      ],
      "metadata": {
        "id": "zZoAz-bhDhK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Duration\n",
        "data = [x for x in durations if x <= 100]\n",
        "\n",
        "# Creating a histogram with bins=8\n",
        "hist, bin_edges = np.histogram(data, bins=4, density=True)\n",
        "\n",
        "# Midpoints of bins\n",
        "bin_midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "\n",
        "# Generating a smooth curve\n",
        "x_smooth = np.linspace(bin_midpoints.min(), bin_midpoints.max(), 30000)\n",
        "y_smooth = make_interp_spline(bin_midpoints, hist)(x_smooth)\n",
        "\n",
        "# Calculate the area under the y_smooth curve\n",
        "area_under_curve = simps(y_smooth, x_smooth)\n",
        "\n",
        "# Normalize y_smooth to make it a PDF\n",
        "y_smooth_pdf = y_smooth / area_under_curve\n",
        "\n",
        "\n",
        "blink_data['duration'] = {'x_smooth': x_smooth, 'y_smooth_pdf': y_smooth_pdf}"
      ],
      "metadata": {
        "id": "iY8DI9DCChoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1XToteuszHUoSdSusmGn2prAhN1epdCbs\" width=\"500\" alt=\"eye_bd.png\">\n",
        "<img src=\"https://drive.google.com/uc?id=1GmZgmwoPhjq295bbjyOFFhX41d3CQLBr\" width=\"500\" alt=\"eye_bd.png\">\n"
      ],
      "metadata": {
        "id": "BXZJC8ZmaBa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store blink data pdfs to json file\n",
        "import json\n",
        "\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "with open(\"eye_data.json\", \"w\") as outfile:\n",
        "    json.dump(blink_data, outfile, cls=NumpyEncoder)"
      ],
      "metadata": {
        "id": "N03lYxWwCkwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthesize eye related blendshape values"
      ],
      "metadata": {
        "id": "Ced1DknB9abm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################## Skewed Generalized Normal Distribution ########################\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from scipy.special import gamma\n",
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "# Define the PDF of the Generalized Normal Distribution\n",
        "def gennorm_pdf(x, beta, mean, sigma):\n",
        "    return np.exp(-np.abs((x - mean) / sigma)**beta) / (2 * sigma * gamma(1/beta) * (1/beta)**(1/beta))\n",
        "\n",
        "# Define a skewing function using the CDF of the normal distribution\n",
        "def skewing_function(x, alpha):\n",
        "    return 2 * norm.cdf(alpha * x)\n",
        "\n",
        "# Internal function to calculate the amplitude A\n",
        "def _calculate_amplitude(beta, max_value, sigma, y_min, mean, alpha):\n",
        "    def objective_function(A):\n",
        "        y_values = A * gennorm_pdf(x_values, beta, mean, sigma) * skewing_function(x_values, alpha) + y_min\n",
        "        return np.abs(max(y_values) - max_value)\n",
        "\n",
        "    x_values = np.linspace(mean - 5*sigma, mean + 5*sigma, 1000)\n",
        "    result = minimize_scalar(objective_function)\n",
        "    return result.x\n",
        "\n",
        "# Modified function to calculate the skewed GND PDF\n",
        "def skewed_gennorm_pdf(x, beta, max_value, sigma, y_min, mean, alpha=5):\n",
        "    A = _calculate_amplitude(beta, max_value, sigma, y_min, mean, alpha)\n",
        "    return A * gennorm_pdf(x, beta, mean, sigma) * skewing_function(x, alpha) + y_min\n",
        "###########################################################################################"
      ],
      "metadata": {
        "id": "gULtlmCYLuzY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################### Helper Functions to Generate Random Blinks ########################\n",
        "def is_too_close(new_x, selected_x, min_distance):\n",
        "    for point in selected_x:\n",
        "        if abs(new_x - point) < min_distance:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def segment_and_normalize_pdf(x, y_pdf, x_range):\n",
        "    indices = (x >= x_range[0]) & (x <= x_range[1])\n",
        "    x_segment = x[indices]\n",
        "    y_pdf_segment = y_pdf[indices]\n",
        "    area = simps(y_pdf_segment, x_segment)\n",
        "    y_pdf_segment_normalized = y_pdf_segment / area\n",
        "    return x_segment, y_pdf_segment_normalized\n",
        "\n",
        "def random_points(x, y, n=1):\n",
        "    cdf = cumtrapz(y, x, initial=0)\n",
        "    cdf /= cdf[-1]  # Normalize\n",
        "    inverse_cdf = interp1d(cdf, x)\n",
        "    random_samples = np.random.rand(n)\n",
        "    return inverse_cdf(random_samples)\n",
        "\n",
        "def random_peaks(x_smooth, y_smooth_pdf, num_points):\n",
        "    length = 1 / num_points\n",
        "    min_distance = length / 2\n",
        "    ranges = [(i * length, (i + 1) * length) for i in range(num_points)]\n",
        "    selected_x = []\n",
        "\n",
        "    # Random points fall in different interval\n",
        "    for x_range in ranges:\n",
        "        x_segment, y_pdf_segment = segment_and_normalize_pdf(x_smooth, y_smooth_pdf, x_range)\n",
        "        attempts = 0\n",
        "        # Neighboring points shouldn't be too close to each other\n",
        "        while attempts < 10:\n",
        "            random_x = random_points(x_segment, y_pdf_segment)[0]\n",
        "            if not is_too_close(random_x, selected_x, min_distance):\n",
        "                selected_x.append(random_x)\n",
        "                break\n",
        "            attempts += 1\n",
        "    return selected_x\n",
        "#################################### End of Helper Functions ####################################\n",
        "\n",
        "\n",
        "####################### Helper Functions to Concatenate Distribution Curves #####################\n",
        "def find_second_peak_index(curve, mean):\n",
        "    argmax = np.argmax(curve[mean:])\n",
        "    return mean + argmax\n",
        "\n",
        "# Find the first intersection point between two curves after xt. Returns the x-value of the first intersection point.\n",
        "def find_first_intersection(x, curve1, curve2, xt):\n",
        "    for i in range(xt, len(x) - 1):\n",
        "        if (curve1[i] - curve2[i]) * (curve1[i+1] - curve2[i+1]) <= 0:\n",
        "            return x[i]\n",
        "    return None\n",
        "#################################### End of Helper Functions ####################################\n",
        "\n",
        "\n",
        "############################### Helper Functions for Perlin noise ###############################\n",
        "# Generate perlin noise\n",
        "def generate_perlin_noise(x, y):\n",
        "    dy = np.gradient(y, x)\n",
        "    threshold = 0.1\n",
        "    smooth_regions = np.abs(dy) < threshold\n",
        "    noise = PerlinNoise(octaves=0.3)\n",
        "    scale = 0.1\n",
        "    y_noise = np.array([noise([xi * scale]) if smooth else 0 for xi, smooth in zip(x, smooth_regions)])\n",
        "\n",
        "    return y_noise\n",
        "#################################### End of Helper Functions ####################################"
      ],
      "metadata": {
        "id": "oDVFyHTq9yqN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Eyes Open Method**\n",
        "1.   Calculate the number of blinks n = duration / blink_average_time\n",
        "2.   Randomly generate n blink peak frames, n durations\n",
        "3.   Use skewed generalized normal distribution to generate curve for each blink and look-down, combine them\n",
        "4.   Add perlin noise\n",
        "5.   Smooth and scale to get eye squint and pitch curves\n",
        "\n",
        "**Eyes Closed Method**\n",
        "1.   Use skewed generalized normal distribution to generate eye blink curve that contains a long eye closing and the eye look-down curve\n",
        "2.   Randomly generate a quick blink in the beginning or end, combine the curves    \n",
        "3.   Add perlin noise\n",
        "4.   Smooth and scale to get eye squint and pitch curves\n"
      ],
      "metadata": {
        "id": "F6PAD2IfbC4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('eye_data.json', 'r') as file:\n",
        "    blink_data = json.load(file)\n",
        "\n",
        "with open('models.pickle', 'rb') as handle:\n",
        "      models = pickle.load(handle)\n",
        "\n",
        "# second number if the user specified duration in unit seconds, 60 fps\n",
        "duration = int(60 * 5.5)\n",
        "# user can specify if they want the eyes to be open or closed\n",
        "eyes_open = True\n",
        "# use can specify openness from 0 to 1\n",
        "openness = 0.8\n",
        "\n",
        "jaw_open_max_value = openness\n",
        "jaw_open_beta = models[\"JawOpen_beta\"].predict([1, jaw_open_max_value])[0]\n",
        "jaw_open_mean = models[\"JawOpen_mean\"].predict([1, duration])[0]\n",
        "jaw_open_sigma = models[\"JawOpen_sigma\"].predict([1, duration])[0]\n",
        "jaw_open_y_min = models[\"JawOpen_y_min\"].predict([1, duration, jaw_open_max_value])[0]\n",
        "\n",
        "x = np.linspace(0, duration+1, duration)\n",
        "if eyes_open:\n",
        "    # Calculate the number of blinks\n",
        "    num_points = round(duration/blink_data['avg_time'])\n",
        "\n",
        "    # Randomly generate blink peaks and duration\n",
        "    selected_peak = random_peaks(np.asarray(blink_data['peak']['x_smooth']), np.asarray(blink_data['peak']['y_smooth_pdf']), num_points)\n",
        "    selected_peak = np.sort((np.array(selected_peak) * duration).astype(int))\n",
        "\n",
        "    selected_duration = (random_points(np.asarray(blink_data['duration']['x_smooth']), np.asarray(blink_data['duration']['y_smooth_pdf']), num_points)).astype(int)\n",
        "    if min(selected_duration) >= 20:\n",
        "        idx = np.argmax(selected_duration)\n",
        "        selected_duration[idx] = random.randint(8, 19)\n",
        "\n",
        "    # Use skewed generalized normal distribution to generate curve for each blink and look-down, combine them\n",
        "    eye_blink = np.zeros(x.shape)\n",
        "    eye_lookdown = np.zeros(x.shape)\n",
        "    alpha = 20\n",
        "    prev_mean = 0\n",
        "    inter_x = 0\n",
        "    inter_x_look = 0\n",
        "    for i in range(num_points):\n",
        "        if i == 0:\n",
        "            y_min = random.uniform(0.05, 0.15)\n",
        "        elif i != (num_points - 1):\n",
        "            y_min = random.uniform(0.2, 0.3)\n",
        "        mean = selected_peak[i]\n",
        "        max_value = random.uniform(0.8, 1)\n",
        "        sigma = selected_duration[i]/2\n",
        "        beta = selected_duration[i]/5.65\n",
        "        cur_blink = skewed_gennorm_pdf(x, beta, max_value, sigma, y_min, mean, alpha)\n",
        "        tmp = skewed_gennorm_pdf(x, beta, max_value - y_min, sigma, y_min, mean, alpha)\n",
        "        cur_lookdown = np.minimum(cur_blink, 1 - tmp)\n",
        "\n",
        "        if eye_blink.all() == 0:\n",
        "            eye_blink = cur_blink\n",
        "            eye_lookdown = cur_lookdown\n",
        "        else:\n",
        "            inter_x = find_first_intersection(x, eye_blink, cur_blink, prev_mean)\n",
        "            inter_x_look = find_first_intersection(x, eye_lookdown, cur_lookdown, second_peak_idx)\n",
        "            if inter_x is not None:\n",
        "                idx = np.where(x >= inter_x)[0][0]\n",
        "                eye_blink[idx:] = cur_blink[idx:]\n",
        "            if inter_x_look is not None:\n",
        "                idx_look = np.where(x >= inter_x_look)[0][0]\n",
        "                eye_lookdown[idx_look:] = cur_lookdown[idx_look:]\n",
        "        prev_mean = mean\n",
        "        second_peak_idx = find_second_peak_index(cur_lookdown, mean)\n",
        "\n",
        "    # Smoothly decrease the last part of the eyeblink curve\n",
        "    b = duration\n",
        "    a = second_peak_idx\n",
        "    decrease_factors = np.linspace(eye_blink[a], 0.05, b - a)\n",
        "    eye_blink[a:b] = eye_blink[a:b] * decrease_factors\n",
        "    eye_lookdown[a:b] = eye_lookdown[a:b] * decrease_factors\n",
        "\n",
        "    # Add noise to make eye blinks more natural\n",
        "    noise1 = generate_perlin_noise(x, eye_blink)\n",
        "    noise2 = generate_perlin_noise(x, eye_lookdown)\n",
        "    eye_blink_noisy = eye_blink + 0.1 * noise1\n",
        "    eye_lookdown_noisy = eye_lookdown * 0.98 + 0.1 * noise2 - 0.02\n",
        "    # Smooth and scale to get eye squint and pitch curves\n",
        "    squint = 0.1 + 0.1 * eye_lookdown_noisy\n",
        "    half = (min(eye_lookdown) - min(squint))/2\n",
        "    pitch = (eye_lookdown_noisy - min(eye_lookdown))/2 + min(eye_lookdown) - half\n",
        "    # Brow curves\n",
        "    brow = skewed_gennorm_pdf(x, jaw_open_beta, jaw_open_max_value/2, jaw_open_sigma - 10, jaw_open_y_min, jaw_open_mean+10)\n",
        "\n",
        "if not eyes_open:\n",
        "    # Use skewed generalized normal distribution to generate eye blink curve with a long eye closing and the eye look-down curve\n",
        "    beta = 50\n",
        "    max_value = random.uniform(0.95, 1)\n",
        "    sigma = jaw_open_sigma + 10\n",
        "    y_min = random.uniform(0.05, 0.1)\n",
        "    mean = jaw_open_mean\n",
        "    alpha = 20\n",
        "\n",
        "    eye_blink = skewed_gennorm_pdf(x, beta, max_value, sigma, y_min, mean, alpha)\n",
        "    tmp = skewed_gennorm_pdf(x, beta, max_value - y_min, sigma, y_min, mean, alpha)\n",
        "    eye_lookdown = np.minimum(eye_blink, 1 - tmp)\n",
        "    frames = jaw_open_mean - jaw_open_sigma\n",
        "\n",
        "    # Randomly add one blink before or after the eye-closing process\n",
        "    if frames > 20:\n",
        "        combined_range = list(range(5, int(frames))) + list(range(int(jaw_open_mean + jaw_open_sigma), duration - 5))\n",
        "        selected_peak = random.choice(combined_range)\n",
        "        selected_duration = random.randint(8, 11)\n",
        "\n",
        "        mean = selected_peak\n",
        "        max_value = random.uniform(0.8, 1)\n",
        "        sigma = selected_duration/2\n",
        "        beta = selected_duration/5.65\n",
        "\n",
        "        eye_blink_rand = skewed_gennorm_pdf(x, beta, max_value, sigma, y_min, mean, alpha)\n",
        "        eye_blink = np.maximum(eye_blink, eye_blink_rand)\n",
        "        tmp = skewed_gennorm_pdf(x, beta, max_value, sigma, y_min, mean, alpha)\n",
        "        eye_lookdown_rand = np.minimum(eye_blink_rand, 1 - tmp)\n",
        "        eye_lookdown = np.maximum(eye_lookdown, eye_lookdown_rand)\n",
        "\n",
        "    # Add noise to make eye closed more natural\n",
        "    noise1 = generate_perlin_noise(x, eye_blink)\n",
        "    noise2 = generate_perlin_noise(x, eye_lookdown)\n",
        "    eye_blink_noisy = eye_blink + 0.1 * noise1\n",
        "    eye_lookdown_noisy = eye_lookdown * 0.98 + 0.1 * noise2 - 0.02\n",
        "    # Smooth and scale to get eye squint and pitch curves\n",
        "    squint = 0.1 + 0.1 * eye_lookdown_noisy\n",
        "    half = (min(eye_lookdown) - min(squint))/2\n",
        "    pitch = (eye_lookdown_noisy - min(eye_lookdown))/2 + min(eye_lookdown) - half\n",
        "    # Brow curves\n",
        "    brow = skewed_gennorm_pdf(x, jaw_open_beta, jaw_open_max_value/4*3, jaw_open_sigma - 10, jaw_open_y_min, jaw_open_mean+10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, brow , label='BrowDownLeft/BrowDownRight')\n",
        "plt.plot(x, eye_blink_noisy , label='EyeBlinkLeft/EyeBlinkRight')\n",
        "plt.plot(x, squint , label='EyeSquintLeft/EyeSquintRight')\n",
        "plt.plot(x, eye_lookdown_noisy , label='EyeLookDownLeft/EyeLookDownRight')\n",
        "plt.plot(x, pitch , label='LeftEyePitch/RightEyePitch')\n",
        "plt.xlabel('Time Frame')\n",
        "plt.ylabel('Blendshape Value')\n",
        "plt.title('Eye-related Blendshape')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9KAU_bd891p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1Iq0S-Fc_jUfXRVRqZ6Obzo0tM48wbBR9\" width=\"500\" alt=\"eye_bd.png\">\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1EI6NnTQaShutrMBgMkYbHAC4SzD4l5q2\" width=\"500\" alt=\"eye_bd.png\">\n",
        "\n"
      ],
      "metadata": {
        "id": "eVigmOAzkD_i"
      }
    }
  ]
}